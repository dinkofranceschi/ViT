{"format": "torch", "nodes": [{"name": "patch_embed", "id": 3025788099840, "class_name": "PatchEmbed(\n  (proj): Conv2d(3, 384, kernel_size=(4, 4), stride=(4, 4))\n)", "parameters": [["proj.weight", [384, 3, 4, 4]], ["proj.bias", [384]]], "output_shape": [[128, 64, 384]], "num_parameters": [18432, 384]}, {"name": "transformer", "id": 3025788099456, "class_name": "Performer(\n  (encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttentionPerformer(\n          (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n        )\n        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): TransformerEncoderLayer(\n        (self_attn): MultiheadAttentionPerformer(\n          (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n        )\n        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (2): TransformerEncoderLayer(\n        (self_attn): MultiheadAttentionPerformer(\n          (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n        )\n        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (3): TransformerEncoderLayer(\n        (self_attn): MultiheadAttentionPerformer(\n          (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n        )\n        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  )\n)", "parameters": [["encoder.layers.0.self_attn.in_proj_weight", [1152, 384]], ["encoder.layers.0.self_attn.in_proj_bias", [1152]], ["encoder.layers.0.self_attn.out_proj.weight", [384, 384]], ["encoder.layers.0.self_attn.out_proj.bias", [384]], ["encoder.layers.0.linear1.weight", [1536, 384]], ["encoder.layers.0.linear1.bias", [1536]], ["encoder.layers.0.linear2.weight", [384, 1536]], ["encoder.layers.0.linear2.bias", [384]], ["encoder.layers.0.norm1.weight", [384]], ["encoder.layers.0.norm1.bias", [384]], ["encoder.layers.0.norm2.weight", [384]], ["encoder.layers.0.norm2.bias", [384]], ["encoder.layers.1.self_attn.in_proj_weight", [1152, 384]], ["encoder.layers.1.self_attn.in_proj_bias", [1152]], ["encoder.layers.1.self_attn.out_proj.weight", [384, 384]], ["encoder.layers.1.self_attn.out_proj.bias", [384]], ["encoder.layers.1.linear1.weight", [1536, 384]], ["encoder.layers.1.linear1.bias", [1536]], ["encoder.layers.1.linear2.weight", [384, 1536]], ["encoder.layers.1.linear2.bias", [384]], ["encoder.layers.1.norm1.weight", [384]], ["encoder.layers.1.norm1.bias", [384]], ["encoder.layers.1.norm2.weight", [384]], ["encoder.layers.1.norm2.bias", [384]], ["encoder.layers.2.self_attn.in_proj_weight", [1152, 384]], ["encoder.layers.2.self_attn.in_proj_bias", [1152]], ["encoder.layers.2.self_attn.out_proj.weight", [384, 384]], ["encoder.layers.2.self_attn.out_proj.bias", [384]], ["encoder.layers.2.linear1.weight", [1536, 384]], ["encoder.layers.2.linear1.bias", [1536]], ["encoder.layers.2.linear2.weight", [384, 1536]], ["encoder.layers.2.linear2.bias", [384]], ["encoder.layers.2.norm1.weight", [384]], ["encoder.layers.2.norm1.bias", [384]], ["encoder.layers.2.norm2.weight", [384]], ["encoder.layers.2.norm2.bias", [384]], ["encoder.layers.3.self_attn.in_proj_weight", [1152, 384]], ["encoder.layers.3.self_attn.in_proj_bias", [1152]], ["encoder.layers.3.self_attn.out_proj.weight", [384, 384]], ["encoder.layers.3.self_attn.out_proj.bias", [384]], ["encoder.layers.3.linear1.weight", [1536, 384]], ["encoder.layers.3.linear1.bias", [1536]], ["encoder.layers.3.linear2.weight", [384, 1536]], ["encoder.layers.3.linear2.bias", [384]], ["encoder.layers.3.norm1.weight", [384]], ["encoder.layers.3.norm1.bias", [384]], ["encoder.layers.3.norm2.weight", [384]], ["encoder.layers.3.norm2.bias", [384]], ["encoder.norm.weight", [384]], ["encoder.norm.bias", [384]]], "output_shape": [[65, 128, 384]], "num_parameters": [442368, 1152, 147456, 384, 589824, 1536, 589824, 384, 384, 384, 384, 384, 442368, 1152, 147456, 384, 589824, 1536, 589824, 384, 384, 384, 384, 384, 442368, 1152, 147456, 384, 589824, 1536, 589824, 384, 384, 384, 384, 384, 442368, 1152, 147456, 384, 589824, 1536, 589824, 384, 384, 384, 384, 384, 384, 384]}, {"name": "norm", "id": 3025788100272, "class_name": "LayerNorm((384,), eps=1e-06, elementwise_affine=True)", "parameters": [["weight", [384]], ["bias", [384]]], "output_shape": [[128, 65, 384]], "num_parameters": [384, 384]}, {"name": "head", "id": 3025788099648, "class_name": "Linear(in_features=384, out_features=100, bias=True)", "parameters": [["weight", [100, 384]], ["bias", [100]]], "output_shape": [[128, 100]], "num_parameters": [38400, 100]}], "edges": []}